{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Logistic Regression, and how does it differ from Linear\n",
        "Regression?\n",
        "    -> Logistic Regression is a statistical method used for classification problems, where the output is categorical (e.g., yes/no, 0/1). It uses the logistic (sigmoid) function to map predicted values to probabilities between 0 and 1. Unlike Linear Regression, which predicts continuous numerical values, Logistic Regression predicts the probability of a class and then assigns the class label based on a threshold (commonly 0.5).\n",
        "\n",
        "2. Explain the role of the Sigmoid function in Logistic Regression.\n",
        "    -> In Logistic Regression, the Sigmoid function transforms the linear combination of input features into a value between 0 and 1, representing the probability of belonging to a particular class. This mapping allows the model to handle classification tasks by setting a decision threshold (usually 0.5) to assign class labels from the predicted probabilities.\n",
        "\n",
        "3.  What is Regularization in Logistic Regression and why is it needed?\n",
        "    -> Regularization in Logistic Regression is a technique used to prevent overfitting by adding a penalty term to the loss function, which discourages the model from assigning excessively large weights to features. It helps improve the model’s generalization on unseen data by controlling complexity, with common types being L1 (Lasso) and L2 (Ridge) regularization.\n",
        "\n",
        "4. What are some common evaluation metrics for classification models, and\n",
        "why are they important?\n",
        "    -> Common evaluation metrics for classification models include Accuracy, Precision, Recall, F1-Score, and the ROC-AUC score. These metrics are important because they provide different perspectives on model performance—accuracy measures overall correctness, precision and recall assess performance on positive predictions, F1-score balances precision and recall, and ROC-AUC evaluates the model’s ability to distinguish between classes across thresholds—helping choose the most suitable model for the task.\n",
        "                "
      ],
      "metadata": {
        "id": "7QwKAR0PPrDx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dehRbbNCPjOw",
        "outputId": "02478f6b-f971-4aa7-8676-a0bc007345f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.956140350877193\n"
          ]
        }
      ],
      "source": [
        "#5. Write a Python program that loads a CSV file into a Pandas DataFrame,splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "# (Use Dataset from sklearn package)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model = LogisticRegression(max_iter=5000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.\n",
        "# (Use Dataset from sklearn package)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=5000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Model Coefficients:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7olD59FROif",
        "outputId": "13f9d6e0-ba5b-4b05-cbe3-abe46a123f71"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.956140350877193\n",
            "Model Coefficients: [[ 1.0274368   0.22145051 -0.36213488  0.0254667  -0.15623532 -0.23771256\n",
            "  -0.53255786 -0.28369224 -0.22668189 -0.03649446 -0.09710208  1.3705667\n",
            "  -0.18140942 -0.08719575 -0.02245523  0.04736092 -0.04294784 -0.03240188\n",
            "  -0.03473732  0.01160522  0.11165329 -0.50887722 -0.01555395 -0.016857\n",
            "  -0.30773117 -0.77270908 -1.42859535 -0.51092923 -0.74689363 -0.10094404]]\n",
            "Intercept: [28.64871395]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import classification_report\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=5000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H99TFN4R1MK",
        "outputId": "23ff9408-42da-4040-b12b-031ad6b71022"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation accuracy.\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "model = LogisticRegression(solver='saga', max_iter=5000)\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbfGa4NtSQXw",
        "outputId": "5ea921c8-800a-42e2-b417-d2f5ba51565f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 0.01, 'penalty': 'l1'}\n",
            "0.9142857142857144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9. Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling.\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model_no_scaling = LogisticRegression(max_iter=5000)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "acc_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaling = LogisticRegression(max_iter=5000)\n",
        "model_scaling.fit(X_train_scaled, y_train)\n",
        "y_pred_scaling = model_scaling.predict(X_test_scaled)\n",
        "acc_scaling = accuracy_score(y_test, y_pred_scaling)\n",
        "\n",
        "print(acc_no_scaling)\n",
        "print(acc_scaling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNz2LFIbS7NT",
        "outputId": "ade30a37-83dc-4ca0-894a-943dc95b98ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.956140350877193\n",
            "0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Imagine you are working at an e-commerce company that wants to\n",
        "predict which customers will respond to a marketing campaign. Given an imbalanced\n",
        "dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.\n",
        "\n",
        "    -> For this marketing campaign problem, I’d start by exploring and cleaning the data to fix any missing or incorrect values. I’d then scale the features so they are on a similar range, as Logistic Regression works better with standardized inputs. Since only 5% of customers respond, I’d handle the imbalance using either class_weight='balanced' in Logistic Regression or oversampling techniques like SMOTE to create more responder samples.\n",
        "\n",
        "    Next, I’d use GridSearchCV to tune important hyperparameters like C and penalty to get the best-performing model. For evaluation, I’d apply stratified cross-validation to maintain the class ratio in splits and focus on metrics such as precision, recall, F1-score, and ROC-AUC, along with the confusion matrix to understand misclassifications. Finally, I’d present the results in a simple way, showing the trade-off between identifying more responders and keeping campaign costs reasonable."
      ],
      "metadata": {
        "id": "MyGQ90WZT37a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NyRBSzHKTkWw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}